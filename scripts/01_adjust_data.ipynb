{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2443d5ac-8330-4459-9a24-1bc2b0fbc985",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Introdução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18e42c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install traquitanas --upgrade\n",
    "#!pip3 install -r requirements.txt\n",
    "#!/usr/local/bin/python -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf6de30-c5dc-4990-9264-8ac47abc4759",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "import shutil\n",
    "import folium\n",
    "import fnmatch\n",
    "import pandas as pd\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301f81eb-a5b7-4902-b626-4e369d196744",
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import ogr\n",
    "from folium import plugins\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c63fa9-aada-4f19-b7e8-cf3a06358306",
   "metadata": {},
   "outputs": [],
   "source": [
    "from traquitanas.geo import layers as tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f494c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paths import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9211387-dfb6-4694-956e-f1407e713716",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Inicialmente extraímos todos os arquivos de dentro do zip \"Shape.zip\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e463bf3-9a88-4219-9abe-7924dc981d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "zipfile_path = input_path / 'Shapes.zip'\n",
    "\n",
    "with ZipFile(zipfile_path, 'r') as zip_obj:    \n",
    "    zip_obj.extractall(temp_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfab907c-c5f0-49f7-8005-05b321010fea",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Uma vez com os arquivos soltos, foi possível observar grande desorganização dos arquivos. Não há qualquer padrão de nomenclatura. Alguns *shapefiles* existem para algumas nascentes, enquanto para outra snão existe.<br>\n",
    "Como o objetivo principal do trabalho é identificar a localização das 56 nascentes que são mencionadas no TAC, optou-se por concentrar os esforços nestas feições."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747d56a6-06db-4f6e-b077-1dac624b53f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_shps = []\n",
    "\n",
    "for root, dirs, files in os.walk(temp_path):\n",
    "    if os.path.basename(root).startswith('Nascente'):\n",
    "        #print(f'\\n{root}')\n",
    "        for file in fnmatch.filter(files, '*.shp'):\n",
    "            #print(f'> {file}')\n",
    "            list_shps.append(file)\n",
    "            pass\n",
    "\n",
    "list_shps = list(set(list_shps))\n",
    "list_shps.sort()\n",
    "list_shps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831662e5-3925-46cb-b961-435ce7d3f71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_shps = list(set([x.name for x in list(temp_path.glob('Nascente*/**/*.shp'))]))\n",
    "list_shps.sort()\n",
    "pprint.pprint(list_shps)\n",
    "\n",
    "a = list_shps[4]\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8198532d-61c2-4ea3-8b1f-b3a97cb47565",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_files = list(set([x.name for x in list(temp_path.glob(f'Nascente*'))]))\n",
    "list_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886cfaa9-0045-4542-9753-9931e128899a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539ce3e1-ef13-4ef7-90d9-88c353d8d31f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2f8e70-118b-47a1-880b-3466e6b811c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "#     for root, dirs, files in os.walk(in_path):\n",
    "#         if os.path.basename(root).startswith('Nascente'):\n",
    "#             for file in fnmatch.filter(files, '*.shp'):\n",
    "#                 if file in [shp]:\n",
    "#                     # Read\n",
    "#                     temp = os.path.join(root, file)\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "#                     gdf = gpd.read_file(temp)\n",
    "#                     gdf.columns = [x.lower() for x in gdf.columns]\n",
    "\n",
    "#                     # Delete Fields\n",
    "#                     #for col in ['Id', 'in_path', 'nascente']:\n",
    "#                     gdf.drop([\n",
    "#                         'Id', 'in_path',\n",
    "#                         'nascente', 'Nascente',\n",
    "#                         'numero', 'x', 'y',\n",
    "#                         'BUFF_DIST', 'buff_dist',\n",
    "#                         'nascente_1'\n",
    "#                         'nascente_1', 'nascente_2',\n",
    "#                         'nascente_3', 'nascente_4',\n",
    "#                         'nascente_5'],\n",
    "#                         axis=1,\n",
    "#                         errors='ignore',\n",
    "#                         inplace=True,\n",
    "#                     )\n",
    "                    \n",
    "#                     # Add Fields\n",
    "#                     gdf['in_path'] = temp\n",
    "#                     dirname = os.path.dirname(temp)\n",
    "#                     dirname = os.path.basename(dirname)\n",
    "#                     nascente_number = int(dirname.split(' ', maxsplit=1)[-1])\n",
    "#                     gdf['nascente'] = nascente_number\n",
    "\n",
    "#                     # Save Output\n",
    "#                     gdf.to_file(temp)\n",
    "\n",
    "#     # Lista Files\n",
    "#     print(gdf.columns)\n",
    "#     list_files = []                \n",
    "#     for root, dirs, files in os.walk(in_path):\n",
    "#         if os.path.basename(root).startswith('Nascente'):\n",
    "#             for file in fnmatch.filter(files, '*.shp'):\n",
    "#                 if file in [shp]:\n",
    "#                     temp = os.path.join(root, file)\n",
    "#                     list_files.append(temp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b00dba-c66d-40fe-a3ab-819f1f69091e",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Junta shapefiles por Nome\n",
    "\n",
    "Com a lista dos possíveis nomes de shapefiles, juntou-se todos os arquivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0121f3ef-2ee7-4e7e-b8ab-362b5dab7d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_shp_by_name(shp, in_path, out_path):\n",
    "    \"\"\"\n",
    "    in_path: pasta root que tem os shapefiles\n",
    "    out_path: pasta que salva\n",
    "    \n",
    "    \"\"\"\n",
    "    # Add Fields\n",
    "    list_files = list(set([x for x in list(in_path.glob(f'Nascente*/**/{shp}'))]))\n",
    "        \n",
    "    # Combine all shapefiles\n",
    "    gdf = gpd.GeoDataFrame(\n",
    "        pd.concat(\n",
    "            [gpd.read_file(i) for i in list_files],\n",
    "            ignore_index=True\n",
    "        ),\n",
    "        crs=gpd.read_file(list_files[0]).crs\n",
    "    )\n",
    "    \n",
    "    # Adjust Columns\n",
    "    gdf.columns = [x.lower() for x in gdf.columns]\n",
    "\n",
    "    # Delete Fields\n",
    "    gdf.drop(\n",
    "        [\n",
    "            'Id',\n",
    "            'in_path',\n",
    "            'nascente',\n",
    "            'Nascente',\n",
    "            'numero',\n",
    "            'x',\n",
    "            'y',\n",
    "            'BUFF_DIST',\n",
    "            'buff_dist',\n",
    "            'nascente_1'\n",
    "            'nascente_1',\n",
    "            'nascente_2',\n",
    "            'nascente_3',\n",
    "            'nascente_4',\n",
    "            'nascente_5'\n",
    "        ],\n",
    "        axis=1,\n",
    "        errors='ignore',\n",
    "        inplace=True,\n",
    "    )\n",
    "\n",
    "    # Add Fields\n",
    "    # gdf['in_path'] = temp\n",
    "    # dirname = os.path.dirname(temp)\n",
    "    # dirname = os.path.basename(dirname)\n",
    "    # nascente_number = int(dirname.split(' ', maxsplit=1)[-1])\n",
    "    # gdf['nascente'] = nascente_number\n",
    "\n",
    "    # Combine all shapefiles\n",
    "    gdf = gpd.GeoDataFrame(\n",
    "        pd.concat(\n",
    "            [gpd.read_file(i) for i in list_files],\n",
    "            ignore_index=True\n",
    "        ),\n",
    "        crs=gpd.read_file(list_files[0]).crs\n",
    "    )\n",
    "\n",
    "    # Save Output\n",
    "    geopackage = shp.replace('shp', 'gpkg')\n",
    "    geopackage_file = out_path / f'{geopackage}'\n",
    "    geopackage_file.unlink()\n",
    "    gdf.to_file(geopackage_file, driver=\"GPKG\")\n",
    "    \n",
    "    #display(gdf)\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c74de2-d2f6-4435-a968-df08120b92d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for shp in list_shps:\n",
    "    gdf = merge_shp_by_name(shp, temp_path, geo_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa71593-0412-4ef3-8eac-fdcfca6ceb20",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Junta shapefiles Específicos\n",
    "\n",
    "Após juntar todos os shapefiles em pastas, notei a existência de shapefiles que tem o mesmo tema, porém continham nomes distintos (por exemplo, \"app.shp\" e \"App.shp\").<br>\n",
    "Esse problema na nomenclatura dos arquivos, impediu que os arquivos fossem unificados e, portanto, foi necessário escrever uma função que juntava os shapefiles, mantendo apenas o primeiro e deletando os restantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9014e59-cf9b-4459-9a8a-8ac75401222f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_shp_specific(list_files):\n",
    "    \"\"\"\n",
    "    Une shapefiles específicos, sobrepondo o primeiro da lista...\n",
    "    Deletando os demais...\n",
    "    \"\"\"\n",
    "    # Concatena\n",
    "    gdf = gpd.GeoDataFrame(\n",
    "        pd.concat(\n",
    "            [gpd.read_file(i) for i in list_files],\n",
    "            ignore_index=True\n",
    "        ),\n",
    "        crs=gpd.read_file(list_files[0]).crs\n",
    "    )\n",
    "\n",
    "    # Deleta Others Files\n",
    "    driver = ogr.GetDriverByName('ESRI Shapefile')\n",
    "    for file in list_files[1:]:\n",
    "        if os.path.exists(file):\n",
    "            driver.DeleteDataSource(file)\n",
    "            print(f'\"{file}\" deletado!!')\n",
    "        else:\n",
    "            print(f'\"{file}\" não existe!')\n",
    "\n",
    "    # Save Output\n",
    "    gdf.to_file(os.path.join(list_files[0]))\n",
    "    return gdf.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcee883-102f-4457-aba5-9943833a51ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_shp_specific(\n",
    "    [\n",
    "        os.path.join(shps_path, 'APP.shp'),\n",
    "        os.path.join(shps_path, 'APP_nascente.shp'),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9832705e-33f8-47d8-90af-76f09158ccf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_shp_specific(\n",
    "    [\n",
    "        os.path.join(shps_path, 'Area_conservacao.shp'),\n",
    "        os.path.join(shps_path, 'area_Conservacao.shp'),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b488e56-2cd4-4274-9ed7-f7bd59a150af",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_shp_specific(\n",
    "    [\n",
    "        os.path.join(shps_path, 'area_drenagem.shp'),\n",
    "        os.path.join(shps_path, 'Area_Drenagem.shp'),\n",
    "        os.path.join(shps_path, 'Area_drenagem.shp'),        \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8729ae2c-0870-4cc2-a490-a3bc3fad5a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_shp_specific(\n",
    "    [\n",
    "        os.path.join(shps_path, 'Recuperacao_curso_agua.shp'),\n",
    "        os.path.join(shps_path, 'Recuperacao_curso_dagua.shp'),\n",
    "        os.path.join(shps_path, 'Recuperacao_cursodagua.shp'),        \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949bb926-1fac-4832-aa6c-22ef4d16481e",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Deleta Shapefiles\n",
    "\n",
    "Após juntar o material que considerei útil para a etapa do meu trabalho, foi possível deletar o restante do material."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cab1d1-b261-407d-98a9-ee0320a612e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_shp(list_files):\n",
    "    \"\"\"\n",
    "    Delete Lista de Shapefiles\n",
    "    \"\"\"\n",
    "    # Deleta Others Files\n",
    "    driver = ogr.GetDriverByName('ESRI Shapefile')\n",
    "    for file in list_files[1:]:\n",
    "        if os.path.exists(file):\n",
    "            driver.DeleteDataSource(file)\n",
    "            print(f'\"{file}\" deletado!!')\n",
    "        else:\n",
    "            print(f'\"{file}\" não existe!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfd9ba9-9bc5-4a2e-862a-495ba4f972fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_files = [\n",
    "    # Lixo\n",
    "    os.path.join(shps_path, 'APP_total.shp'),\n",
    "\n",
    "    # Interessa?\n",
    "    os.path.join(shps_path, 'Geologia.shp'),\n",
    "    #os.path.join(shps_path, 'Nascente.shp'),\n",
    "    os.path.join(shps_path, 'Pontos_geofisica.shp'),\n",
    "    os.path.join(shps_path, 'Recomposicao.shp'),\n",
    "    os.path.join(shps_path, 'Recuperacao_nascente.shp'),\n",
    "    os.path.join(shps_path, 'Uso_solo_APP.shp'),\n",
    "    os.path.join(shps_path, 'Uso_solo_app_curso_dagua.shp'),\n",
    "    os.path.join(shps_path, 'Uso_solo_app_nasc.shp'),\n",
    "    os.path.join(shps_path, 'Uso_solo_area_drenagem.shp'),\n",
    "    os.path.join(shps_path, 'Uso_solo_curso_agua.shp'),\n",
    "    os.path.join(shps_path, 'Uso_solo_hidrografia.shp'),\n",
    "]\n",
    "\n",
    "delete_shp(list_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715b4d17-5e56-4318-b31f-99a50d46776c",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(temp_path, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49551a51-edf8-4392-8679-54c38bf3fcf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-autonumbering": true,
  "vscode": {
   "interpreter": {
    "hash": "2bdda54bf0f28693adab761d90c570fb0a7faa3609b365313c0b5d078440c060"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
